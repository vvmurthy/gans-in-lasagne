{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Invertible Conditional GANs in Theano + Lasagne\n",
    "\n",
    "This implements [Invertible Conditional GANs for Image Editing](https://arxiv.org/abs/1611.06355) from November 2016. \n",
    "\n",
    "This implementation is based off of the author's Torch [implementation](https://github.com/Guim3/IcGAN), and the Lasagne DCGAN [Gist](https://gist.github.com/f0k/738fa2eedd9666b78404ed1751336f56) and MNIST [demo](https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This was developed using:\n",
    "\n",
    "* [Theano 0.9.0rc4](https://github.com/Theano/Theano)\n",
    "* [Lasagne 0.2dev](https://github.com/Lasagne/Lasagne)\n",
    "* [Scipy 0.13](https://www.scipy.org)\n",
    "* [Matplotlib 1.3.1](https://github.com/matplotlib/matplotlib)\n",
    "* [Numpy v1.13](https://github.com/numpy/numpy)\n",
    "* (OPTIONAL) [Tabulate](https://pypi.python.org/pypi/tabulate) - This module can be used to display a list containing input, output dimensions of each layer of the GAN. \n",
    "\n",
    "Compatibility with other version modules is not guaranteed, especially Lasagne < 0.2.\n",
    "\n",
    "## 1. Training the Model\n",
    "\n",
    "Our implementation of ICGAN is trained in two steps.\n",
    "1. Train the Generator + Discriminator\n",
    "2. Train Encoder Z + Y, using minibatches of generated images from the trained generator\n",
    "\n",
    "This is in contrast with the author's implementation that generates a single set of images to train on. Our implementation is also based around hardware constraints, so images are loaded in per minibatch into memory. Thus our implementation can be run on modest hardware though training may take more time.\n",
    "\n",
    "On a NVIDIA GTX 1060 6GB GPU, the GAN models took about 40 minutes per epoch to train. The encoders took about 4-5 minutes per epoch to train. \n",
    "\n",
    "### 1.1 Datasets supported\n",
    "\n",
    "Currently, we support:\n",
    "\n",
    "Dataset | Number of Images | Attributes|\n",
    "--- | --- | --- |\n",
    "[CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) | ~200000 | 18 attributes from Perarnau et al |\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist/) | 60000 | number written |\n",
    "\n",
    "We recommend using the aligned and cropped datasets, though in theory any dataset can be used. \n",
    "\n",
    "We supply a set of pretrained models + images of results from each epoch. These models were generated using learning rates and batchsizes given by the author (0.0002 and 64). \n",
    "\n",
    "**Using the training function**\n",
    "\n",
    "1. Download CelebA aligned + cropped images, along with the files `list_attr_celeba.txt` and `list_eval_partition.txt` [here](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). \n",
    "2. ``` \n",
    "\tpython train.py FOLDER_NAME CELEBA_DIR\n",
    "```\n",
    "\n",
    "*` FOLDER_NAME ` is the name of the folder to store trained models in. The default name is `first_test`\n",
    "*` CELEBA_DIR ` is the directory containing the CELEBA images + text files. The default directory is `os.getcwd()`\n",
    "* `LEARNING_RATE ` is the learning rate of the model. Default is 0.0002\n",
    "* `\n",
    "\n",
    "## 2. Testing the Model\n",
    "\n",
    "This test will generate an interpolation, a swap, and a reconstruction image and save them in `folder_name/images`.\n",
    "\n",
    "1. ``` \n",
    "\tpython test.py FOLDER_NAME CELEBA_DIR\n",
    "```\n",
    " \n",
    "Where `FOLDER_NAME` and `CELEBA_DIR` are exactly as specified in the section on training the model. Pretrained modelsprovided with this implementation are used by default.\n",
    "\n",
    "# Results\n",
    "\n",
    "These results are from the pretrained models provided, trained according to default specifications.\n",
    "\n",
    "### Reconstructions of Real Faces \n",
    "\n",
    "### Swapped Faces\n",
    "\n",
    "### Interpolation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Notes to self\n",
    "dataset_init needs to return X_files_train, y_train, X_files_val, y_val, X_files_test, y_test, lab. so make mnist into files after tar gz\n",
    "\n",
    "load_files (memory batch loader) needs to be overhauled to be a \"main\" function called from train / test that does if x dataset load_x_dataset\n",
    "\n",
    "each train file should be able to handle varying channels, input sizes, and hyperparameters for training. Same with test\n",
    "\n",
    "utils should be able to create examples that are generic enough\n",
    "\n",
    "directory structure should be:\n",
    "dataset_init - loads in dataset initially\n",
    "load_files - main function, but allows different sorts of files to be loaded\n",
    "archive- files that have been majorly revised since original version\n",
    "models- builds of models and training functions\n",
    "train- training functions for various models\n",
    "test - testing functions (different figures generation). Each test corresponds to a different train e.g. icgan goes with icgan test, began goes with began test.\n",
    "\n",
    "one main file outside the directories will be run, running config and picking proper train file to run\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
